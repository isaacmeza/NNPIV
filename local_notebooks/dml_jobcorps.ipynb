{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegression, LogisticRegressionCV, LinearRegression,\\\n",
    "    ElasticNet, ElasticNetCV, MultiTaskElasticNet, MultiTaskElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mliv.dgps_mediated as dgps\n",
    "from mliv.ensemble import EnsembleIV, EnsembleIVStar\n",
    "from mliv.rkhs import ApproxRKHSIVCV, RKHSIVCV\n",
    "from mliv.shape import LipschitzShapeIV, ShapeIV\n",
    "from mliv.linear import OptimisticHedgeVsOptimisticHedge, StochasticOptimisticHedgeVsOptimisticHedge\n",
    "from mliv.linear import L2OptimisticHedgeVsOGD, L2ProxGradient\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.cluster import KMeans\n",
    "#from mliv.neuralnet.deepiv_fit import deep_iv_fit\n",
    "from mliv.neuralnet.rbflayer import gaussian, inverse_multiquadric\n",
    "from mliv.neuralnet import AGMM, KernelLayerMMDGMM, CentroidMMDGMM, KernelLossAGMM, MMDGMM\n",
    "from mliv.tsls import tsls, regtsls\n",
    "\n",
    "p = 0.1  # dropout prob of dropout layers throughout notebook\n",
    "n_hidden = 100  # width of hidden layers throughout notebook\n",
    "\n",
    "# For any method that use a projection of z into features g(z)\n",
    "g_features = 100\n",
    "\n",
    "# The kernel function\n",
    "kernel_fn = gaussian\n",
    "# kernel_fn = inverse_multiquadric\n",
    "\n",
    "# Training params\n",
    "learner_lr = 1e-4\n",
    "adversary_lr = 1e-4\n",
    "learner_l2 = 1e-3\n",
    "adversary_l2 = 1e-4\n",
    "adversary_norm_reg = 1e-3\n",
    "n_epochs = 300\n",
    "bs = 100\n",
    "sigma = 2.0 / g_features\n",
    "n_centers = 100\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dml_mediated import DML_mediated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('../data/JCdata.csv', delimiter=' ', header=0)\n",
    "\n",
    "# Bind covariates\n",
    "X = df[[\"female\", \"age\", \"race_white\", \"race_black\", \"race_hispanic\", \"educ_geddiploma\",\n",
    "        \"educ_hsdiploma\", \"ntv_engl\", \"marstat_divorced\", \"marstat_separated\",\n",
    "        \"marstat_livetogunm\", \"marstat_married\", \"haschldY0\", \"everwkd\", \"mwearn\",\n",
    "        \"hohhd0\", \"nonres\", \"g10\", \"g10missdum\", \"work_dad_didnotwork\", \"g2\", \"g5\",\n",
    "        \"g7\", \"welfare_child\", \"welfare_childmissdum\", \"h1_fair_poor\", \"h2\", \"h29\",\n",
    "        \"h5\", \"h5missdum\", \"h7\", \"h7missdum\", \"i1\", \"i10\"]][df[\"e12missdum\"] == 0].values\n",
    "\n",
    "df['a'] = df['d'][df[\"e12missdum\"] == 0].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Create proxies\n",
    "Z = df[[\"e12\", \"e37\"]][df[\"e12missdum\"] == 0].values\n",
    "W = df[[\"e32\", \"e8_recruitersoffice\"]][df[\"e12missdum\"] == 0].values\n",
    "\n",
    "\n",
    "# Outcome\n",
    "Y = df[[\"y\"]][df[\"e12missdum\"] == 0].values\n",
    "# Mediator\n",
    "M = df[[\"m\"]][df[\"e12missdum\"] == 0].values\n",
    "# Treatment\n",
    "D = df[[\"a\"]][df[\"e12missdum\"] == 0].values\n",
    "\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkhs_model = ApproxRKHSIVCV(kernel_approx='nystrom', n_components=100,\n",
    "                           kernel='rbf', gamma=.1, delta_scale='auto',\n",
    "                           delta_exp=.4, alpha_scales=np.geomspace(1, 10000, 10), cv=5)\n",
    "\n",
    "def _get_learner(n_t):\n",
    "    return nn.Sequential(nn.Dropout(p=p), nn.Linear(n_t, n_hidden), nn.LeakyReLU(),\n",
    "                         nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "\n",
    "def _get_adversary(n_z):\n",
    "    return nn.Sequential(nn.Dropout(p=p), nn.Linear(n_z, n_hidden), nn.LeakyReLU(),\n",
    "                         nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "\n",
    "def _get_adversary_g(n_z):\n",
    "    return nn.Sequential(nn.Dropout(p=p), nn.Linear(n_z, n_hidden), nn.LeakyReLU(),\n",
    "                         nn.Dropout(p=p), nn.Linear(n_hidden, g_features), nn.ReLU())\n",
    "\n",
    "\n",
    "agmm_1 = AGMM(_get_learner(37),_get_adversary(37))\n",
    "agmm_2 = AGMM(_get_learner(36),_get_adversary(36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_rkhs = DML_mediated(Y, D, M, W, X, Z,\n",
    "                        model1 = ApproxRKHSIVCV(kernel_approx='nystrom', n_components=1000,\n",
    "                           kernel='rbf', gamma=.1, delta_scale='auto',\n",
    "                           delta_exp=.4, alpha_scales=np.geomspace(1, 10000, 10), cv=10),\n",
    "                        model2 = ApproxRKHSIVCV(kernel_approx='nystrom', n_components=100,\n",
    "                           kernel='rbf', gamma=.1, delta_scale='auto',\n",
    "                           delta_exp=.4, alpha_scales=np.geomspace(1, 10000, 10), cv=5),\n",
    "                        modelq1 = ApproxRKHSIVCV(kernel_approx='nystrom', n_components=100,\n",
    "                           kernel='rbf', gamma=.1, delta_scale='auto',\n",
    "                           delta_exp=.4, alpha_scales=np.geomspace(1, 10000, 10), cv=5),\n",
    "                        modelq2 = ApproxRKHSIVCV(kernel_approx='nystrom', n_components=100,\n",
    "                           kernel='rbf', gamma=.1, delta_scale='auto',\n",
    "                           delta_exp=.4, alpha_scales=np.geomspace(1, 10000, 10), cv=5),\n",
    "                n_folds=30, n_rep=1, CHIM = False, prop_score=LogisticRegression(max_iter=1000))\n",
    "                \n",
    "dml_rkhs_chim = DML_mediated(Y, D, M, W, X, Z,\n",
    "                        model1 = rkhs_model,\n",
    "                        model2 = rkhs_model,\n",
    "                        modelq1 = rkhs_model,\n",
    "                        modelq2 = rkhs_model,\n",
    "                n_folds=5, n_rep=3, CHIM = True, prop_score=LogisticRegression(max_iter=1000))\n",
    "\n",
    "dml_rkhs_ipw = DML_mediated(Y, D, M, W, X, Z,\n",
    "                        model1 = rkhs_model,\n",
    "                        model2 = rkhs_model,\n",
    "                        modelq1 = rkhs_model,\n",
    "                        modelq2 = rkhs_model,\n",
    "                n_folds=5, n_rep=3, estimator='IPW', prop_score=LogisticRegression(max_iter=1000))\n",
    "\n",
    "dml_rkhs_ipw_chim = DML_mediated(Y, D, M, W, X, Z,\n",
    "                        model1 = rkhs_model,\n",
    "                        model2 = rkhs_model,\n",
    "                        modelq1 = rkhs_model,\n",
    "                        modelq2 = rkhs_model,\n",
    "                n_folds=5, n_rep=3, estimator='IPW', CHIM = True, prop_score=LogisticRegression(max_iter=1000))                \n",
    "\n",
    "dml_agmm = DML_mediated(Y, D, M, W, X, Z,\n",
    "                        model1 = agmm_1,\n",
    "                        model2 = agmm_2,\n",
    "                        modelq1 = agmm_2,\n",
    "                        modelq2 = agmm_1,\n",
    "                        n_folds=5, n_rep=1,\n",
    "                        CHIM = False,\n",
    "                        prop_score=LogisticRegression(max_iter=1000),\n",
    "                        nn_1 = True,\n",
    "                        nn_2 = True,\n",
    "                        nn_q1 = True,\n",
    "                        nn_q2 = True,\n",
    "                        fitargs1 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4, 'adversary_norm_reg' : 1e-3},\n",
    "                        fitargs2 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4},\n",
    "                        fitargsq1 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4},\n",
    "                        fitargsq2 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4},\n",
    "                        opts = {'lin_degree': 1, 'burnin': 200})\n",
    "\n",
    "dml_2sls = DML_mediated(Y, D, M, W, X, Z,\n",
    "                        model1 = tsls(),\n",
    "                        model2 = tsls(),\n",
    "                        modelq1 = tsls(),\n",
    "                        modelq2 = tsls(),\n",
    "                n_folds=10, n_rep=3, prop_score=LogisticRegression(max_iter=1000))\n",
    "\n",
    "\n",
    "dml_rfiv = DML_mediated(Y, D, M, W, X, Z,\n",
    "                        model1 = EnsembleIV(n_iter=200, max_abs_value=2),\n",
    "                        model2 = EnsembleIV(n_iter=200, max_abs_value=2),\n",
    "                        modelq1 = EnsembleIV(n_iter=200, max_abs_value=2),\n",
    "                        modelq2 = EnsembleIV(n_iter=200, max_abs_value=2),\n",
    "                n_folds=5, n_rep=1, prop_score=LogisticRegression(max_iter=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dml_2sls.dml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dml_rkhs.dml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dml_rkhs_chim.dml())\n",
    "print(dml_rkhs_ipw.dml())\n",
    "print(dml_rkhs_ipw_chim.dml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dml_agmm.dml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubly_robust(X, T, Y):\n",
    "    ps = LogisticRegression(C=1e6, max_iter=1000).fit(X, T).predict_proba(X)[:, 1]\n",
    "    mask1 = np.where(T==1)[0]\n",
    "    mask0 = np.where(T==0)[0]\n",
    "    mu0 = LinearRegression().fit(X[mask0,], Y[mask0]).predict(X)\n",
    "    mu1 = LinearRegression().fit(X[mask1,], Y[mask1]).predict(X)\n",
    "    return (np.mean(T * (Y - mu1) / ps + mu1), np.mean((1 - T) * (Y - mu0) / (1 - ps) + mu0))\n",
    "\n",
    "\n",
    "y1, y0 = doubly_robust(X, D, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(y1)\n",
    "print(y0)\n",
    "print(y1 - y0)\n",
    "print(0.0895757991453447-y0)\n",
    "print(0.01544137589055832-y0)\n",
    "print(0.14523434238839902-y0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
