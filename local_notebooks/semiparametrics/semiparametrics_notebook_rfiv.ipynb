{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# DML (mediated) with RandomForest-based Ensemble IV \n",
    "# =========================================================\n",
    "\n",
    "# ---- Limit BLAS/OpenMP threads BEFORE importing heavy libs ----\n",
    "import os as os\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"VECLIB_MAXIMUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "\n",
    "# ---- Standard libs ----\n",
    "import sys\n",
    "import time\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- Third-party ----\n",
    "import numpy as np\n",
    "from threadpoolctl import threadpool_limits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Keep native libraries (BLAS/OpenMP) to 1 thread\n",
    "threadpool_limits(1)\n",
    "\n",
    "# ---- Local repo imports (adjust path if needed) ----\n",
    "sys.path.append(str(Path.cwd() / \"../../simulations\"))\n",
    "import dgps_mediated as dgps  \n",
    "\n",
    "from nnpiv.ensemble import EnsembleIV, Ensemble2IV  \n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier  \n",
    "from nnpiv.semiparametrics import DML_mediated  \n",
    "\n",
    "# PyTorch presence for reproducibility reporting\n",
    "try:\n",
    "    import torch  \n",
    "    TORCH_OK = True\n",
    "except Exception:\n",
    "    TORCH_OK = False\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Reproducibility helpers\n",
    "# -----------------------\n",
    "def seed_everything(seed: int = 123) -> None:\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if TORCH_OK:\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "        try:\n",
    "            torch.set_num_threads(1)\n",
    "            torch.set_num_interop_threads(1)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "seed_everything(123)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Resource print utility\n",
    "# -----------------------\n",
    "def print_resources():\n",
    "    \"\"\"Print basic compute resource info (CPU, GPU, library versions).\"\"\"\n",
    "    cpu_cores = os.cpu_count()\n",
    "    pyver = sys.version.split()[0]\n",
    "    npver = np.__version__\n",
    "    torch_info = \"not installed\"\n",
    "    gpu_info = \"CUDA: not available\"\n",
    "    if TORCH_OK:\n",
    "        torch_info = torch.__version__\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                name = torch.cuda.get_device_name(0)\n",
    "            except Exception:\n",
    "                name = \"Unknown GPU\"\n",
    "            gpu_info = f\"CUDA: available — {name}\"\n",
    "    print(\"=== Compute resources ===\")\n",
    "    print(f\"Python: {pyver}\")\n",
    "    print(f\"NumPy: {npver}\")\n",
    "    print(f\"PyTorch: {torch_info}\")\n",
    "    print(f\"CPU cores: {cpu_cores}\")\n",
    "    print(gpu_info)\n",
    "    print(\"Thread caps (env):\")\n",
    "    for k in [\"OMP_NUM_THREADS\",\"OPENBLAS_NUM_THREADS\",\"MKL_NUM_THREADS\",\n",
    "              \"VECLIB_MAXIMUM_THREADS\",\"NUMEXPR_NUM_THREADS\"]:\n",
    "        print(f\"  {k}={os.environ.get(k, 'unset')}\")\n",
    "    print(f\"Platform: {platform.platform()}\")\n",
    "    print(\"=========================\\n\")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Result formatter\n",
    "# -----------------------\n",
    "def summarize_dml_result(name: str, result, elapsed: float):\n",
    "    \"\"\"\n",
    "    Accepts result from .dml() and prints θ, SE, 95% CI when available.\n",
    "    Compatible with returns like (theta, var, ci) or (theta, var, ci, cov).\n",
    "    \"\"\"\n",
    "    if isinstance(result, tuple):\n",
    "        if len(result) == 3:\n",
    "            theta, var, ci = result\n",
    "            cov = None\n",
    "        elif len(result) == 4:\n",
    "            theta, var, ci, cov = result\n",
    "        else:\n",
    "            print(f\"[{name}] time={elapsed:.2f}s — result={result}\")\n",
    "            return\n",
    "    else:\n",
    "        print(f\"[{name}] time={elapsed:.2f}s — result={result}\")\n",
    "        return\n",
    "\n",
    "    theta = np.atleast_1d(theta).astype(float)\n",
    "    var = np.atleast_1d(var).astype(float)\n",
    "    se = np.sqrt(var)\n",
    "    ci = np.array(ci, dtype=float) if ci is not None else None\n",
    "\n",
    "    def fmt_arr(a):\n",
    "        return f\"{float(a[0]):.4f}\" if a.size == 1 else np.array2string(a, precision=4)\n",
    "\n",
    "    print(f\"[{name}] time={elapsed:.2f}s\")\n",
    "    print(f\"  theta: {fmt_arr(theta)}\")\n",
    "    print(f\"  SE   : {fmt_arr(se)}\")\n",
    "    if ci is not None:\n",
    "        if ci.ndim == 1 and ci.size == 2:\n",
    "            print(f\"  95% CI: [{ci[0]:.4f}, {ci[1]:.4f}]\")\n",
    "        else:\n",
    "            print(f\"  95% CI: {np.array2string(ci, precision=4)}\")\n",
    "    if 'cov' in locals() and cov is not None:\n",
    "        print(f\"  (cov shape: {cov.shape})\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Compute resources ===\n",
      "Python: 3.10.18\n",
      "NumPy: 2.2.6\n",
      "PyTorch: 2.5.0\n",
      "CPU cores: 112\n",
      "CUDA: not available\n",
      "Thread caps (env):\n",
      "  OMP_NUM_THREADS=1\n",
      "  OPENBLAS_NUM_THREADS=1\n",
      "  MKL_NUM_THREADS=1\n",
      "  VECLIB_MAXIMUM_THREADS=1\n",
      "  NUMEXPR_NUM_THREADS=1\n",
      "Platform: Linux-4.18.0-553.44.1.el8_10.x86_64-x86_64-with-glibc2.28\n",
      "=========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Print resources\n",
    "# -----------------------\n",
    "print_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ground truth (for log reference) ===\n",
      "True parameter for E[Y(1,M(0))] ≈ 4.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Data generation\n",
    "# =========================================================\n",
    "# Function dictionary (for reference):\n",
    "# {'abs': 0, '2dpoly': 1, 'sigmoid': 2, 'sin': 3, 'frequent_sin': 4, 'abs_sqrt': 5,\n",
    "#  'step': 6, '3dpoly': 7, 'linear': 8, 'rand_pw': 9, 'abspos': 10, 'sqrpos': 11,\n",
    "#  'band': 12, 'invband': 13, 'steplinear': 14, 'pwlinear': 15, 'exponential': 16}\n",
    "\n",
    "fn_number = 0\n",
    "tau_fn = dgps.get_tau_fn(fn_number)\n",
    "tauinv_fn = dgps.get_tauinv_fn(fn_number)  # kept for parity with your original script\n",
    "W, Z, X, M, D, Y, tau_fn = dgps.get_data(2000, tau_fn)\n",
    "\n",
    "# If you have a known ground-truth estimand for this DGP, put it here:\n",
    "TRUE_PARAM = 4.05\n",
    "print(f\"=== Ground truth (for log reference) ===\\nTrue parameter for E[Y(1,M(0))] ≈ {TRUE_PARAM:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:26<00:00, 29.20s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential (MR) with EnsembleIV] time=146.01s\n",
      "  theta: 3.8579\n",
      "  SE   : 4.9284\n",
      "  95% CI: [3.6419, 4.0739]\n",
      "\n",
      "Rep: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [09:38<00:00, 115.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Simultaneous (MR) with Ensemble2IV] time=578.79s\n",
      "  theta: 3.7609\n",
      "  SE   : 4.9921\n",
      "  95% CI: [3.5422, 3.9797]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Model builders (fresh instances to avoid state leakage)\n",
    "# =========================================================\n",
    "def build_ensemble_iv():\n",
    "    \"\"\"Fresh single-stage EnsembleIV used in sequential MR (both stages & q-models).\"\"\"\n",
    "    return EnsembleIV(n_iter=200, max_abs_value=2)\n",
    "\n",
    "def build_ensemble2_iv():\n",
    "    \"\"\"Fresh simultaneous Ensemble2IV with RF components.\"\"\"\n",
    "    adversary = RandomForestRegressor(\n",
    "        n_estimators=50, max_depth=None, bootstrap=True,\n",
    "        min_samples_leaf=40, min_impurity_decrease=0.001\n",
    "    )\n",
    "    learnerg = RandomForestClassifier(\n",
    "        n_estimators=50, max_depth=None, criterion=\"gini\",\n",
    "        bootstrap=False, min_samples_leaf=40, min_impurity_decrease=0.001\n",
    "    )\n",
    "    learnerh = RandomForestClassifier(\n",
    "        n_estimators=40, max_depth=None, criterion=\"gini\",\n",
    "        bootstrap=False, min_samples_leaf=40, min_impurity_decrease=0.001\n",
    "    )\n",
    "    return Ensemble2IV(\n",
    "        n_iter=500, max_abs_value=2,\n",
    "        adversary=adversary, learnerg=learnerg, learnerh=learnerh,\n",
    "        n_burn_in=100\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1) Sequential estimator (MR) with EnsembleIV\n",
    "# =========================================================\n",
    "dml_seq = DML_mediated(\n",
    "    Y, D, M, W, Z, X,\n",
    "    estimator=\"MR\",\n",
    "    estimand=\"E[Y(1,M(0))]\",\n",
    "    # fresh models for both stages and q-models\n",
    "    model1=[build_ensemble_iv(), build_ensemble_iv()],\n",
    "    modelq1=[build_ensemble_iv(), build_ensemble_iv()],\n",
    "    nn_1=[False,False],\n",
    "    nn_q1=[False,False],\n",
    "    fitargs1=[None, None],\n",
    "    fitargsq1=[None, None],\n",
    "    prop_score=LogisticRegression(max_iter=2000),\n",
    "    n_folds=5, n_rep=1,\n",
    ")\n",
    "t0 = time.perf_counter()\n",
    "res_seq = dml_seq.dml()\n",
    "t1 = time.perf_counter()\n",
    "summarize_dml_result(\"Sequential (MR) with EnsembleIV\", res_seq, t1 - t0)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2) Simultaneous estimator (MR) with Ensemble2IV\n",
    "# =========================================================\n",
    "dml_sim = DML_mediated(\n",
    "    Y, D, M, W, Z, X,\n",
    "    estimator=\"MR\",\n",
    "    estimand=\"E[Y(1,M(0))]\",\n",
    "    model1=build_ensemble2_iv(),   # simultaneous nested model\n",
    "    nn_1=False,\n",
    "    # you used EnsembleIV for the q-models; keep that but use fresh instances\n",
    "    modelq1=[build_ensemble_iv(), build_ensemble_iv()],\n",
    "    nn_q1=[False, False],\n",
    "    fitargsq1=[None, None],\n",
    "    prop_score=LogisticRegression(max_iter=2000),\n",
    "    n_folds=5, n_rep=1,\n",
    ")\n",
    "t0 = time.perf_counter()\n",
    "res_sim = dml_sim.dml()\n",
    "t1 = time.perf_counter()\n",
    "summarize_dml_result(\"Simultaneous (MR) with Ensemble2IV\", res_sim, t1 - t0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpiv_venv (3.9.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
