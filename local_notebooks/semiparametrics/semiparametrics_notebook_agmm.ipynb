{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the simulations/mcpy directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../simulations')))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import simulations.dgps_mediated as dgps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.cluster import KMeans\n",
    "from nnpiv.neuralnet.rbflayer import gaussian, inverse_multiquadric\n",
    "from nnpiv.neuralnet import AGMM, AGMM2, AGMM2L2\n",
    "from nnpiv.tsls import tsls, regtsls\n",
    "\n",
    "# Now you can import the module\n",
    "from nnpiv.semiparametrics import DML_mediated\n",
    "\n",
    "p = 0.1  # dropout prob of dropout layers throughout notebook\n",
    "n_hidden = 100  # width of hidden layers throughout notebook\n",
    "\n",
    "\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fn_number = 0\n",
    "tau_fn = dgps.get_tau_fn(fn_number)\n",
    "tauinv_fn = dgps.get_tauinv_fn(fn_number)\n",
    "W, Z, X, M, D, Y, tau_fn = dgps.get_data(2000, tau_fn)\n",
    "\n",
    "V = np.random.rand(Y.shape[0])\n",
    "V = V.reshape(-1, 1)\n",
    "\n",
    "print(np.column_stack((W,X,Z)).shape)\n",
    "ind = np.where(D==0)[0]\n",
    "W0 = W[ind]\n",
    "X0 = X[ind,:]\n",
    "W0_test = np.zeros((1000, 1+X.shape[1]))\n",
    "W0_test += np.median(np.column_stack((X0,W0)), axis=0, keepdims=True)\n",
    "W0_test[:, 2] = np.linspace(np.percentile(\n",
    "            W0[:, 0], 5), np.percentile(W0[:, 0], 95), 1000)\n",
    "\n",
    "# True parameters\n",
    "b_yd = 2.0; b_ym = 1.0; b_yx = np.array([[-1.0],[-1.0]]); b_yu = -1.0; b_yw = 2.0; b_y0 = 2.0\n",
    "b_wx = np.array([[0.2],[0.2]]); b_wu = -0.6; b_w0 = 0.3\n",
    "b_md = -0.3; b_mx = np.array([[-0.5],[-0.5]]); b_mu = 0.4; b_m0 = 0.0\n",
    "    \n",
    "gamma_1w = (b_yw*b_wu + b_yu)/b_wu\n",
    "gamma_1x = b_yw*b_wx + b_yx - gamma_1w*b_wx\n",
    "gamma_1m = b_ym\n",
    "gamma_10 = b_y0 + b_yd + b_yw*b_w0 - gamma_1w*b_w0\n",
    "\n",
    "gamma_0w = (gamma_1m*b_mu + gamma_1w*b_wu)/b_wu\n",
    "gamma_0x = gamma_1m*b_mx + gamma_1w*b_wx + gamma_1x - gamma_0w*b_wx\n",
    "gamma_00 = gamma_10 + gamma_1m*b_m0 + gamma_1w*b_w0 - gamma_0w*b_w0\n",
    "\n",
    "    # True nuisance function\n",
    "expected_te = gamma_00 + tauinv_fn(W0_test)@np.row_stack((gamma_0x, gamma_0w))\n",
    "D_ = D.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_learner(n_t):\n",
    "    return nn.Sequential(nn.Dropout(p=p), nn.Linear(n_t, n_hidden), nn.LeakyReLU(),\n",
    "                         nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "\n",
    "def _get_adversary(n_z):\n",
    "    return nn.Sequential(nn.Dropout(p=p), nn.Linear(n_z, n_hidden), nn.LeakyReLU(),\n",
    "                         nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "\n",
    "agmm_1 = AGMM(_get_learner(4),_get_adversary(4))\n",
    "agmm_2 = AGMM(_get_learner(3),_get_adversary(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:02<00:00, 60.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.3680296, 2.5548935, array([4.297978 , 4.4380813], dtype=float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dml_agmm = DML_mediated(Y, D, M, W, Z, X,\n",
    "                        estimator='OR',\n",
    "                        estimand='E[Y(1,M(0))]',\n",
    "                        model1 = agmm_1,\n",
    "                        model2 = agmm_2,\n",
    "                        modelq1 = agmm_2,\n",
    "                        modelq2 = agmm_1,\n",
    "                        n_folds=5, n_rep=1,\n",
    "                        CHIM = False,\n",
    "                        nn_1 = True,\n",
    "                        nn_2 = True,\n",
    "                        nn_q1 = True,\n",
    "                        nn_q2 = True,\n",
    "                        fitargs1 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4, 'adversary_norm_reg' : 1e-3},\n",
    "                        fitargs2 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4},\n",
    "                        fitargsq1 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4},\n",
    "                        fitargsq2 = {'n_epochs': 300, 'bs': 100, 'learner_lr': 1e-4, 'adversary_lr': 1e-4, 'learner_l2': 1e-3, 'adversary_l2': 1e-4},\n",
    "                        opts = {'lin_degree': 1, 'burnin': 200})\n",
    "\n",
    "\n",
    "print(dml_agmm.dml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3519893\n",
      "4.0187054\n"
     ]
    }
   ],
   "source": [
    "fitargs1 = {\n",
    "    'n_epochs': 300, \n",
    "    'bs': 100, \n",
    "    'learner_lr': 1e-4, \n",
    "    'adversary_lr': 1e-4, \n",
    "    'learner_l2': 1e-3, \n",
    "    'adversary_l2': 1e-4, \n",
    "    'adversary_norm_reg': 1e-3\n",
    "}\n",
    "\n",
    "fitargs2 = {\n",
    "    'n_epochs': 300, \n",
    "    'bs': 100, \n",
    "    'learner_lr': 1e-4, \n",
    "    'adversary_lr': 1e-4, \n",
    "    'learner_l2': 1e-3, \n",
    "    'adversary_l2': 1e-4\n",
    "}\n",
    "\n",
    "Y, D, M, W, X, Z = map(lambda x: torch.Tensor(x), [Y, D, M, W, X, Z])\n",
    "\n",
    "ind = np.where(D == 1)[0]\n",
    "M1 = M[ind]\n",
    "W1 = W[ind]\n",
    "X1 = X[ind, :]\n",
    "Z1 = Z[ind]\n",
    "Y1 = Y[ind]\n",
    "\n",
    "A2 = torch.cat((M1, X1, Z1), 1)\n",
    "A1 = torch.cat((M1, X1, W1), 1)\n",
    "\n",
    "bridge_1 = agmm_1.fit(A2, A1, Y1, **fitargs1)\n",
    "\n",
    "A1 = torch.cat((M, X, W), 1)\n",
    "bridge_1_hat = torch.Tensor(bridge_1.predict(A1.to(device), model='avg', burn_in=200))\n",
    "\n",
    "D, W, X, Z, bridge_1_hat = map(lambda x: torch.Tensor(x), [D, W, X, Z, bridge_1_hat])\n",
    "\n",
    "ind = np.where(D == 0)[0]\n",
    "W0 = W[ind]\n",
    "X0 = X[ind, :]\n",
    "Z0 = Z[ind]\n",
    "bridge_1_hat = bridge_1_hat[ind]\n",
    "\n",
    "B2 = torch.cat((X0, Z0), 1)\n",
    "B1 = torch.cat((X0, W0), 1)\n",
    "\n",
    "bridge_2 = agmm_2.fit(B2, B1, bridge_1_hat, **fitargs2)\n",
    "\n",
    "gamma_0_hat = bridge_2.predict(torch.cat((X, W), 1).to(device), model='avg', burn_in=200)\n",
    "print(np.mean(gamma_0_hat))\n",
    "print(np.var(gamma_0_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor(np.column_stack((M,X,W)), dtype=torch.float32)\n",
    "D = torch.tensor(D_, dtype=torch.float32)\n",
    "E = torch.tensor(np.column_stack((M,X,Z)), dtype=torch.float32)\n",
    "B = torch.tensor(np.column_stack((X,W)), dtype=torch.float32)\n",
    "C = torch.tensor(np.column_stack((X,Z)), dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitargs = {\n",
    "    'n_epochs': 100, \n",
    "    'bs': 100, \n",
    "    'learner_lr': 0.001, \n",
    "    'adversary_lr': 0.001, \n",
    "    'learner_l2': 1e-3, \n",
    "    'adversary_l2': 1e-4\n",
    "}\n",
    "\n",
    "agmm2_model = AGMM2(learnerh = _get_learner(B.shape[1]), learnerg = _get_learner(A.shape[1]),\n",
    "                     adversary1 = _get_adversary(E.shape[1]), adversary2 = _get_adversary(C.shape[1]))\n",
    "\n",
    "\n",
    "agmm2_pred_b, agmm2_pred_a = agmm2_model.fit(A, B, C, E, Y, subsetted=True, subset_ind1=D, **fitargs).predict(B.to(device), A.to(device), model='avg', burn_in=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.143315\n",
      "9.956722\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(agmm2_pred_b))\n",
    "print(np.var(agmm2_pred_b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpiv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
